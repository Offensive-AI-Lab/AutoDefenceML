{"attacks": {"AutoConjugateGradient": {"name": "AutoConjugateGradient", "class_name": "art.attacks.evasion.auto_conjugate_gradient.AutoConjugateGradient", "type": "Evasion", "violation": "Integrity", "assumption": "WB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Medium", "description": "Implementation of the 'Auto Conjugate Gradient' attack. The original implementation is https://github.com/yamamura-k/ACG. | Paper link: https://arxiv.org/abs/2206.09628", "default_max_iter": 100}, "AutoProjectedGradientDescent": {"name": "AutoProjectedGradientDescent", "class_name": "art.attacks.evasion.auto_projected_gradient_descent.AutoProjectedGradientDescent", "type": "Evasion", "violation": "integrity", "assumption": "WB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Medium", "description": "Implementation of the `Auto Projected Gradient Descent` attack. | Paper link: https://arxiv.org/abs/2003.01690", "default_max_iter": 100}, "BasicIterativeMethod": {"name": "BasicIterativeMethod", "class_name": "art.attacks.evasion.iterative_method.BasicIterativeMethod", "type": "Evasion", "violation": "Integrity", "assumption": "WB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Medium", "description": "Implementation of the `Basic Iterative Method` attack. | Paper link: https://arxiv.org/abs/1607.02533", "default_max_iter": 100}, "BoundaryAttack": {"name": "BoundaryAttack", "class_name": "art.attacks.evasion.boundary.BoundaryAttack", "type": "Evasion", "violation": "Integrity", "assumption": "BB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Long", "description": "Implementation of the boundary attack from Brendel et al. (2018). This is a powerful black-box attack that only requires final class prediction. | Paper link: https://arxiv.org/abs/1712.04248", "default_max_iter": 5000}, "BrendelBethgeAttack": {"name": "BrendelBethgeAttack", "class_name": "art.attacks.evasion.brendel_bethge.BrendelBethgeAttack", "type": "Evasion", "violation": "Integrity", "assumption": "BB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Long", "description": "Base class for the Brendel & Bethge adversarial attack [#Bren19], a powerful gradient-based adversarial attack that follows the adversarial boundary (the boundary between the space of adversarial and non-adversarial images as defined by the adversarial criterion) to find the minimum distance to the clean image."}, "CarliniL2Method": {"name": "CarliniL2Method", "class_name": "art.attacks.evasion.carlini.CarliniL2Method", "type": "Evasion", "violation": "integrity", "assumption": "WB", "influence": "Exploritory", "p-norm": "2", "run_time": "Medium", "description": "The L_2 optimized attack of Carlini and Wagner (2016). | Paper link: https://arxiv.org/abs/1608.04644", "default_max_iter": 10}, "DecisionTreeAttack": {"name": "DecisionTreeAttack", "class_name": "art.attacks.evasion.decision_tree_attack.DecisionTreeAttack", "type": "Evasion", "violation": "Integrity", "assumption": "BB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Medium", "description": "Close implementation of Papernot's attack on decision trees following Algorithm 2 and communication with the authors. | Paper link: https://arxiv.org/abs/1605.07277"}, "DeepFool": {"name": "DeepFool", "class_name": "art.attacks.evasion.deepfool.DeepFool", "type": "Evasion", "violation": "Integrity", "assumption": "WB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Long", "description": "Implementation of the attack from Moosavi-Dezfooli et al. (2015). | Paper link: https://arxiv.org/abs/1511.04599", "default_max_iter": 100}, "DPatch": {"name": "DPatch", "class_name": "art.attacks.evasion.dpatch.DPatch", "type": "Evasion", "violation": "integrity", "assumption": "BB", "influence": "Exploritory", "description": "This module implements the adversarial patch attack `DPatch` for object detectors.| Paper link: https://arxiv.org/abs/1806.02299v4", "default_max_iter": 500}, "ElasticNet": {"name": "ElasticNet", "class_name": "art.attacks.evasion.elastic_net.ElasticNet", "type": "Evasion", "violation": "Integrity", "assumption": "WB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Long", "description": "The elastic net attack of Pin-Yu Chen et al. (2018). | Paper link: https://arxiv.org/abs/1709.04114", "default_max_iter": 100}, "FastGradientMethod": {"name": "FastGradientMethod", "class_name": "art.attacks.evasion.fast_gradient.FastGradientMethod", "type": "Evasion", "violation": "Integrity", "assumption": "WB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Short", "description": "This attack was originally implemented by Goodfellow et al. (2015) with the infinity norm | Paper link: https://arxiv.org/abs/1412.6572"}, "FrameSaliencyAttack": {"name": "FrameSaliencyAttack", "class_name": "art.attacks.evasion.frame_saliency.FrameSaliencyAttack", "type": "Evasion", "violation": "Integrity", "assumption": "BB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Medium", "description": "Implementation of the attack framework proposed by Inkawhich et al. (2018). | Paper link: https://arxiv.org/abs/1811.11875"}, "GeoDA": {"name": "GeoDA", "class_name": "art.attacks.evasion.geometric_decision_based_attack.GeoDA", "type": "Evasion", "violation": "Integrity", "assumption": "BB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Long", "description": "Implementation of the Geometric Decision-based Attack (GeoDA), a black-box attack requiring class predictions. | Paper link: https://arxiv.org/abs/2003.06468", "default_max_iter": 10}, "GRAPHITEBlackbox": {"name": "GRAPHITEBlackbox", "class_name": "art.attacks.evasion.graphite.graphite_blackbox.GRAPHITEBlackbox", "type": "Evasion", "violation": "integrity", "assumption": "BB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Long", "description": "Implementation of the hard-label GRAPHITE attack from Feng et al. (2022). | Paper link: https://arxiv.org/abs/2002.07088"}, "HighConfidenceLowUncertainty": {"name": "HighConfidenceLowUncertainty", "class_name": "art.attacks.evasion.hclu.HighConfidenceLowUncertainty", "type": "Evasion", "violation": "Integrity", "assumption": "BB", "p-norm": "2", "run_time": "Long", "influence": "Exploritory", "description": "Implementation of the High-Confidence-Low-Uncertainty (HCLU) adversarial example formulation by Grosse et al. (2018) | Paper link: https://arxiv.org/abs/1812.02606"}, "HopSkipJump": {"name": "HopSkipJump", "class_name": "art.attacks.evasion.hop_skip_jump.HopSkipJump", "type": "Evasion", "violation": "Integrity", "assumption": "BB", "influence": "Exploritory", "p-norm": "2", "run_time": "Long", "description": "Implementation of the HopSkipJump attack from Jianbo et al. (2019). | Paper link: https://arxiv.org/abs/1904.02144", "default_max_iter": 10}, "ImperceptibleASR": {"name": "ImperceptibleASR", "class_name": "art.attacks.evasion.imperceptible_asr.imperceptible_asr.ImperceptibleASR", "type": "Evasion", "violation": "integrity", "assumption": "WB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Medium", "description": "Implementation of the imperceptible attack against a speech recognition model. | Paper link: http://proceedings.mlr.press/v97/qin19a.html"}, "LaserAttack": {"name": "LaserAttack", "class_name": "art.attacks.evasion.laser_attack.laser_attack.LaserAttack", "type": "Evasion", "violation": "Integrity", "assumption": "BB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Medium", "description": "This module implements the `LaserAttack` attack.| Paper link: https://arxiv.org/abs/2103.06504"}, "LowProFool": {"name": "LowProFool", "class_name": "art.attacks.evasion.lowprofool.LowProFool", "type": "Evasion", "violation": "Integrity", "assumption": "WB", "influence": "Exploritory", "p-norm": "2", "run_time": "Long", "description": "`LowProFool` attack. | Paper link: https://arxiv.org/abs/1911.03274"}, "MomentumIterativeMethod": {"name": "MomentumIterativeMethod", "class_name": "art.attacks.evasion.momentum_iterative_method.MomentumIterativeMethod", "type": "Evasion", "violation": "Integrity", "assumption": "WB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Short", "description": "Momentum Iterative Fast Gradient Method attack integrates momentum into the iterative version of FGM and FGSM. | Paper link: https://arxiv.org/abs/1710.06081", "default_max_iter": 100}, "NewtonFool ": {"name": "NewtonFool ", "class_name": "art.attacks.evasion.newtonfool.NewtonFool", "type": "Evasion", "violation": "integrity", "assumption": "WB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Medium", "description": "Implementation of the attack from Uyeong Jang et al. (2017) | Paper link: http://doi.acm.org/10.1145/3134600.3134635", "default_max_iter": 100}, "ProjectedGradientDescent": {"name": "ProjectedGradientDescent", "class_name": "art.attacks.evasion.projected_gradient_descent.projected_gradient_descent.ProjectedGradientDescent", "type": "Evasion", "violation": "Integrity", "assumption": "WB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Short", "description": "The Projected Gradient Descent attack is an iterative method in which, after each iteration, the perturbation is projected on an lp-ball of specified radius (in addition to clipping the values of the adversarial sample so that it lies in the permitted data range). This is the attack proposed by Madry et al. for adversarial training. | Paper link: https://arxiv.org/abs/1706.06083", "default_max_iter": 100}, "PixelThreshold": {"name": "PixelThreshold", "class_name": "art.attacks.evasion.pixel_threshold.PixelThreshold", "type": "Evasion", "violation": "Integrity", "assumption": "BB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Medium", "description": "These attacks were originally implemented by Vargas et al. (2019) & Su et al.(2019). | One Pixel Attack Paper link: https://arxiv.org/abs/1710.08864 | Pixel and Threshold Attack Paper link: https://arxiv.org/abs/1906.06026", "default_max_iter": 100}, "SaliencyMapMethod ": {"name": "SaliencyMapMethod ", "class_name": "art.attacks.evasion.saliency_map.SaliencyMapMethod", "type": "Evasion", "violation": "Integrity", "assumption": "WB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Medium", "description": "Implementation of the Jacobian-based Saliency Map Attack (Papernot et al. 2016). | Paper link: https://arxiv.org/abs/1511.07528"}, "SimBA": {"name": "SimBA", "class_name": "art.attacks.evasion.simba.SimBA", "type": "Evasion", "violation": "integrity", "assumption": "BB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Medium", "description": "This class implements the black-box attack `SimBA`. | Paper link: https://arxiv.org/abs/1905.07121", "default_max_iter": 1000}, "SpatialTransformation": {"name": "SpatialTransformation", "class_name": "art.attacks.evasion.spatial_transformation.SpatialTransformation", "type": "Evasion", "violation": "Integrity", "assumption": "BB", "influence": "Exploritory", "description": "Implementation of the spatial transformation attack using translation and rotation of inputs. | Paper link: https://arxiv.org/abs/1712.02779"}, "SquareAttack": {"name": "SquareAttack", "class_name": "art.attacks.evasion.square_attack.SquareAttack", "type": "Evasion", "violation": "Integrity", "assumption": "BB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Medium", "description": "This class implements the `SquareAttack` attack. | Paper link: https://arxiv.org/abs/1912.00049", "default_max_iter": 100}, "ZooAttack": {"name": "ZooAttack", "class_name": "art.attacks.evasion.zoo.ZooAttack", "type": "Evasion", "violation": "Integrity", "assumption": "BB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Long", "description": "The black-box zeroth-order optimization attack from Pin-Yu Chen et al. (2018) | Paper link: https://arxiv.org/abs/1708.03999", "default_max_iter": 10}, "HopSkipJump_Tabular": {"name": "HopSkipJump_Tabular", "class_name": "art_attacks_plugin.HopSkipJump_Tabular.HopSkipJump", "type": "Evasion", "violation": "Integrity", "assumption": "BB", "influence": "Exploritory", "p-norm": "2", "run_time": "Long", "description": "Implementation of the HopSkipJump attack tabular version by Fraidi Yael Itzhakev. | Paper link: https://arxiv.org/abs/1904.02144", "default_max_iter": 10}, "Boundary_Tabular": {"name": "Boundary_Tabular", "class_name": "art_attacks_plugin.Boundary_Tabular.BoundaryAttack", "type": "Evasion", "violation": "Integrity", "assumption": "BB", "influence": "Exploritory", "p-norm": "inf", "run_time": "Long", "description": "Implementation of the boundary attack tabular version by Fraidi Yael Itzhakev | Paper link: https://arxiv.org/abs/1712.04248", "default_max_iter": 5000}}, "defenses": {"ClassLabels": {"name": "ClassLabels", "class_name": "art.defences.postprocessor.class_labels.ClassLabels", "type": "postprocessor", "description": " Implementation of a postprocessor based on adding class labels to classifier output."}, "GaussianNoise": {"name": "GaussianNoise", "class_name": "art.defences.postprocessor.gaussian_noise.GaussianNoise", "type": "postprocessor", "description": " Implementation of a postprocessor based on adding Gaussian noise to classifier output."}, "HighConfidence": {"name": "HighConfidence", "class_name": "art.defences.postprocessor.high_confidence.HighConfidence", "type": "postprocessor", "description": "  Implementation of a postprocessor based on selecting high confidence predictions to return as classifier output."}, "ReverseSigmoid": {"name": "ReverseSigmoid", "class_name": "art.defences.postprocessor.reverse_sigmoid.ReverseSigmoid", "type": "postprocessor", "description": "  Implementation of a postprocessor based on adding the Reverse Sigmoid perturbation to classifier output."}, "Rounded": {"name": "Rounded", "class_name": "art.defences.postprocessor.rounded.Rounded", "type": "postprocessor", "description": "Implementation of a postprocessor based on rounding classifier output."}, "CutMix": {"name": "CutMix", "class_name": "art.defences.preprocessor.cutmix.cutmix.CutMix", "type": "preprocessor", "description": " Implement the CutMix data augmentation defence approach. | Paper link: https://arxiv.org/abs/1905.04899"}, "CutOut": {"name": "CutOut", "class_name": "art.defences.preprocessor.cutout.cutout.Cutout", "type": "preprocessor", "description": "Implement the Cutout data augmentation defence approach.  | Paper link: https://arxiv.org/abs/1708.04552"}, "Mixup": {"name": "Mixup", "class_name": "art.defences.preprocessor.mixup.mixup.Mixup", "type": "preprocessor", "description": "Implement the Mixup data augmentation defence approach.  | Paper link: https://arxiv.org/abs/1710.09412"}, "FeatureSqueezing": {"name": "FeatureSqueezing", "class_name": "art.defences.preprocessor.feature_squeezing.FeatureSqueezing", "type": "preprocessor", "description": "  Reduces the sensibility of the features of a sample.    | Paper link: https://arxiv.org/abs/1704.01155"}, "GaussianAugmentation": {"name": "GaussianAugmentation", "class_name": "art.defences.preprocessor.gaussian_augmentation.GaussianAugmentation", "type": "preprocessor", "description": " Add Gaussian noise to a dataset in one of two ways: either add noise to each sample (keeping the size of the  original dataset) or perform augmentation by keeping all original samples and adding noisy counterparts."}, "LabelSmoothing": {"name": "LabelSmoothing", "class_name": "art.defences.preprocessor.label_smoothing.LabelSmoothing", "type": "preprocessor", "description": "  Computes a vector of smooth labels from a vector of hard ones.  | Paper link: https://pdfs.semanticscholar.org/b5ec/486044c6218dd41b17d8bba502b32a12b91a.pdf"}, "Resample": {"name": "Resample", "class_name": "art.defences.preprocessor.resample.Resample", "type": "preprocessor", "description": "Implement the resampling defense approach.  Resampling implicitly consists of a step that applies a low-pass filter."}, "SpatialSmoothing": {"name": "SpatialSmoothing", "class_name": "art.defences.preprocessor.spatial_smoothing.SpatialSmoothing", "type": "preprocessor", "description": "Implement the local spatial smoothing defence approach.| Paper link: https://arxiv.org/abs/1704.01155"}, "TotalVarMin": {"name": "TotalVarMin", "class_name": "art.defences.preprocessor.variance_minimization.TotalVarMin", "type": "preprocessor", "description": " Implement the total variance minimization defence approach. | Paper link: https://openreview.net/forum?id=SyJ7ClWCb"}}}