import os
import subprocess
import time
import uuid
import traceback
import asyncio
import datetime
import json
import logging
import shutil
from google.cloud import storage, container_v1
from google.cloud.exceptions import NotFound
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, Any
from fastapi import BackgroundTasks, APIRouter, HTTPException
from fastapi.encoders import jsonable_encoder
from .request_classes import ValidationRequestBody
from .helpers import clean_env, store_on_db, get_from_db, db_log, get_from_db_by_short_id
from ...pre_run.input_validation import InputValidator
from ...pre_run.model_validation import ModelDatasetValidator
from ...pre_run.estimator_match import EstimatorHandler
from ...pre_run.attack_defense_validation import AttackDefenseValidator
from ...user_files.helpers import *
from file_loader.file_handler import FileLoader
from dotenv import load_dotenv
from .gke_utils import GKEUtils


load_dotenv()
router = APIRouter()

PROJECT_ID = os.getenv("PROJECT_ID")
TOPIC = os.getenv("EVAL_TOPIC")
TOPIC_PING = os.getenv("TOPIC_PING")
TOPIC_EVAL = os.getenv("TOPIC_EVAL")
FIRESTORE_DB = os.getenv("FIRESTORE_DB")
FIRESTORE_REPORTS_COLLECTION = os.getenv("FIRESTORE_REPORTS_COLLECTION")
FIRESTORE_VAL_STATUS_COLLECTION = os.getenv("FIRESTORE_VAL_STATUS_COLLECTION")

terraform_directory = "/Library/validation/src/Infrastructure/"
environment_id = os.getenv("ENVIRONMENT") or "MainServer"
if environment_id == "cloud_dev":
    environment_id = "MainServer"

def run_terraform_command_background(command: list, cwd: str) -> subprocess.Popen:
    return subprocess.Popen(
        command,
        cwd=cwd,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        universal_newlines=True
    )


def run_terraform_init_background(terraform_directory: str) -> subprocess.Popen:
    return run_terraform_command_background(["terraform", "init"], terraform_directory)


def run_terraform_apply_background(terraform_directory: str) -> subprocess.Popen:
    return run_terraform_command_background(["terraform", "apply", "-auto-approve"], terraform_directory)


def run_terraform_destroy_background(terraform_directory: str, target: str) -> subprocess.Popen:
    return run_terraform_command_background(["terraform", "destroy", "-target=" + target, "-auto-approve"],
                                            terraform_directory)


def run_terraform_apply():
    try:
        result = subprocess.run(
            ["terraform", "apply", "-auto-approve"],
            cwd=terraform_directory,
            check=True,
            capture_output=True,
            text=True
        )
        db_log(environment_id, "66 - Terraform apply completed successfully.")
        db_log(environment_id, result.stdout)
        return result.stdout
    except subprocess.CalledProcessError as e:
        db_log(environment_id, f"70 - Terraform apply failed with error: {e}")
        db_log(environment_id, json.dumps({"error": str(e)}))
        db_log(environment_id, e.stderr)
        return None


def run_terraform_init():
    try:
        result = subprocess.run(
            ["terraform", "init"],
            cwd=terraform_directory,
            check=True,
            capture_output=True,
            text=True
        )
        db_log(environment_id, "66 - Terraform init completed successfully.")
        db_log(environment_id, result.stdout)
        return result.stdout
    except subprocess.CalledProcessError as e:
        db_log(environment_id, f"70 - Terraform init failed with error: {e}")
        db_log(environment_id, json.dumps({"error": str(e)}))
        db_log(environment_id, e.stderr)
        return None


def add_to_db(user_id, job_id, process_type, timestamp, cluster_name):
    # Add the job details to the MySQL database
    pass


def perform_validation_sync(job_id, request):
    try:
        clean_env()
        request = request.dict()
        user_id = request.get("user_id")
        db_log(environment_id, f"84 - job id: {job_id}")
        cluster_name = f"k8c-{job_id}"
        os.environ["FILES_PATH"] = os.getenv("FILES_PATH_VAL")

        fileloader = FileLoader(metadata=request,
                                path_to_files_dir=get_files_package_root(),
                                path_to_model_files_dir=get_model_package_root(),
                                path_to_dataset_files_dir=get_dataset_package_root(),
                                path_to_dataloader_files_dir=get_dataloader_package_root(),
                                path_to_loss_files_dir=get_loss_package_root(),
                                path_to_req_files_dir=get_req_files_package_root(),
                                from_bucket=os.getenv("FROM_BUCKET"),
                                bucket_name=os.getenv("BUCKET_NAME"),
                                account_service_key_name=os.getenv("ACCOUNT_SERVICE_KEY"))

        input_validator = InputValidator(fileloader_obj=fileloader)
        model_dataset_validator = ModelDatasetValidator(fileloader_obj=fileloader)

        if input_validator.validate():
            validation_status = get_from_db(project_id=PROJECT_ID,
                                            database=FIRESTORE_DB,
                                            collection_name=FIRESTORE_VAL_STATUS_COLLECTION,
                                            document_id=job_id)
            validation_status['process_stage'] = 'Model and dataset validation'
            store_on_db(project_id=PROJECT_ID,
                        database=FIRESTORE_DB,
                        collection_name=FIRESTORE_VAL_STATUS_COLLECTION,
                        document_key=job_id,
                        params=validation_status)
        else:
            raise Exception("User's input not valid")

        if model_dataset_validator.validate():
            validation_status = get_from_db(project_id=PROJECT_ID,
                                            database=FIRESTORE_DB,
                                            collection_name=FIRESTORE_VAL_STATUS_COLLECTION,
                                            document_id=job_id)
            validation_status['process_stage'] = 'Finding compatible attacks and defenses'
            store_on_db(project_id=PROJECT_ID,
                        database=FIRESTORE_DB,
                        collection_name=FIRESTORE_VAL_STATUS_COLLECTION,
                        document_key=job_id,
                        params=validation_status)
        else:
            raise Exception("Model does not match with the dataset!")

        input = input_validator.get_input()
        db_log(environment_id, f"131 - Input to wrap estimator: {input}")
        wrapper = EstimatorHandler(input, fileloader_obj=fileloader)
        db_log(environment_id, f"133 - Starting to wrap model...")
        wrapper.wrap()
        db_log(environment_id, f"135 - Wrap went successfully...")
        estimator = fileloader.get_estimator()

        attack_defense_validator = AttackDefenseValidator(fileloader_obj=fileloader)
        compatible_attacks = attack_defense_validator.get_compatible_attacks(estimator=estimator)
        compatible_defenses = attack_defense_validator.get_compatible_defenses()

        validation_status = {"job_id": job_id, "process_status": "Done",
                             "process_stage": "None",
                             "error": "",
                             "stack trace": "",
                             "compatible_attacks": compatible_attacks,
                             "compatible_defenses": compatible_defenses}
        store_on_db(project_id=PROJECT_ID,
                    database=FIRESTORE_DB,
                    collection_name=FIRESTORE_VAL_STATUS_COLLECTION,
                    document_key=job_id,
                    params=validation_status)

        db_log(environment_id, f"154 - Saved status : {validation_status}")

        with open(get_files_package_root() + "/Estimator_params.json", 'r') as f:
            estimator_params = json.load(f)
        store_on_db(project_id=os.getenv("PROJECT_ID"),
                    database=os.getenv("FIRESTORE_DB"),
                    collection_name=os.getenv("FIRESTORE_ESTIMATOR_COLLECTION"),
                    document_key=job_id,
                    params=estimator_params)
        clean_env()
    except Exception as e:
        error_traceback = traceback.format_exc()
        validation_status = {"job_id": job_id, "process_status": "Failed",
                             "process_stage": "None",
                             "error": str(e),
                             "stack trace": str(error_traceback),
                             "compatible_attacks": [],
                             "compatible_defenses": []}
        store_on_db(project_id=PROJECT_ID,
                    database=FIRESTORE_DB,
                    collection_name=FIRESTORE_VAL_STATUS_COLLECTION,
                    document_key=job_id,
                    params=validation_status)
        if validation_status["process_status"] == "Failed":
            clean_env()


async def perform_validation(job_id, request):
    loop = asyncio.get_event_loop()
    with ThreadPoolExecutor() as executor:
        await loop.run_in_executor(executor, perform_validation_sync, job_id, request)


def set_val_response(job_id):
    validation_status = {"job_id": job_id, "process_status": 'Running',
                         "process_stage": 'Input validation',
                         "error": None,
                         "stack trace": None,
                         "compatible_attacks": None,
                         "compatible_defenses": None}

    store_on_db(project_id=PROJECT_ID,
                database=FIRESTORE_DB,
                collection_name=FIRESTORE_VAL_STATUS_COLLECTION,
                document_key=job_id,
                params=validation_status)


@router.post("/validatetest/")
async def validate(request: ValidationRequestBody, background_tasks: BackgroundTasks):
    try:
        await removelock()
        job_idUuid = str(uuid.uuid4())
        request_dict = request.dict()
        user_id = request_dict['user_id']
        job_id = user_id + "-" + job_idUuid
        short_id = job_idUuid[:6]

        document = {"user_id": request.user_id,
                    "job_id": job_id,
                    "request": jsonable_encoder(request),
                    "background_tasks": jsonable_encoder(background_tasks),
                    "short_id": short_id,
                    "destroy_id": "google_container_node_pool.node-gpu_num_" + short_id,
                    "request_type": 'validate'}

        db_log(environment_id, f"216 - Storing document in DB for job_id: {job_id}")
        store_on_db(project_id=PROJECT_ID,
                    database=FIRESTORE_DB,
                    collection_name="Requests",
                    document_key=job_id,
                    params=document)

        db_log(environment_id, "223 - Fetching terraform file from DB")
        terraformFile = get_from_db(project_id=PROJECT_ID,
                                    database=FIRESTORE_DB,
                                    collection_name="Stuff",
                                    document_id="addGpuServer")

        def write_to_file(file_name, content):
            try:
                with open(file_name, 'w') as f:
                    f.write(content)
                db_log(environment_id, f"235 - Content written to {file_name}")
                db_log(environment_id, f"236 - Content: {content}")

                if os.path.exists(file_name):
                    file_size = os.path.getsize(file_name)
                    db_log(environment_id, f"237 - File {file_name} exists after writing. Size: {file_size} bytes")
                else:
                    db_log(environment_id, f"239 - File {file_name} does not exist after supposed writing")

            except Exception as e:
                db_log(environment_id, f"242 - Error writing to file {file_name}: {str(e)}")
                raise

        newText = terraformFile["json"].replace("XXXX", short_id)
        newText = newText.replace("YYYY", short_id)
        newText = newText.replace("MainServer", short_id)
        db_log(environment_id, f"248 - Modified terraform text: {newText[:100]}...")  # Log first 100 chars

        db_log(environment_id, f"250 - Terraform directory: {terraform_directory}")
        if not os.path.exists(terraform_directory):
            os.makedirs(terraform_directory)
            db_log(environment_id, f"253 - Created terraform directory: {terraform_directory}")

        file_path = os.path.join(terraform_directory, f"new-gpu-server-{short_id}.tf")
        db_log(environment_id, f"256 - Attempting to write file: {file_path}")

        write_to_file(file_path, newText)

        if os.path.exists(file_path):
            file_size = os.path.getsize(file_path)
            db_log(environment_id, f"262 - File {file_path} exists after write_to_file. Size: {file_size} bytes")
        else:
            db_log(environment_id, f"264 - File {file_path} does not exist after write_to_file")

        if terraformFile["runTerraform"]:
            db_log(environment_id, "267 - Adding run_terraform_apply to background tasks")
            background_tasks.add_task(run_terraform_apply)

        # set_val_response(job_id)
        # background_tasks.add_task(perform_validation, job_id, request)

        db_log(environment_id, f"273 - Validate function completed successfully for job_id: {job_id}")
        return {"job_id": job_id}

    except Exception as e:
        error_msg = f"277 - Error in validate function: {str(e)}"
        db_log(environment_id, error_msg)
        raise HTTPException(status_code=500, detail=error_msg)


@router.get("/getid/")
async def getid():
    db_log(environment_id, "283 - get id")
    return environment_id


@router.get("/removelock/")
async def removelock():
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

    try:
        # Initialize the Google Cloud Storage client
        storage_client = storage.Client()

        # Get the bucket
        bucket = storage_client.bucket("cbg-api-bucket")

        # Specify the blob (file) to delete
        blob = bucket.blob("Infrastructure/state/default.tflock")

        # Check if the blob exists
        if blob.exists():
            # Delete the blob
            blob.delete()
            logger.info("Lock file successfully removed")
            return {"message": "Lock file successfully removed"}
        else:
            logger.info("Lock file not found, no action needed")
            return {"message": "Lock file not found, no action needed"}

    except Exception as e:
        logger.error(f"Error checking/removing lock file: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to check/remove lock file: {str(e)}")


@router.get("/listofgpu/")
async def list_gpu():
    try:
        result = subprocess.run(
            ["terraform", "state", "list"],
            cwd=terraform_directory,
            capture_output=True,
            text=True
        )
        return {"gpu_list": result.stdout.split('\n'), "error": result.stderr.split('\n')}
    except subprocess.CalledProcessError as e:
        db_log(environment_id, f"326 - Error during list GPU: {e.stderr}")
        return {"error": str(e)}


@router.get("/removegpu/{gpu_id}")
async def remove_gpu(gpu_id: str):
    destroy_process = run_terraform_destroy_background(terraform_directory, gpu_id)
    db_log(environment_id, f"332 - Terraform destroy for {gpu_id} started in background.")

    return {"message": f"Terraform destroy for {gpu_id} initiated in background"}


@router.get("/get_all_files/")
async def listget_all_files_gpu():
    try:
        # Check if the provided path is a directory
        if not os.path.isdir(terraform_directory):
            raise ValueError(f"{terraform_directory} is not a valid directory")

        # List all files in the directory
        files = []
        for entry in os.listdir(terraform_directory):
            full_path = os.path.join(terraform_directory, entry)
            if os.path.isfile(full_path):  # Only add files (ignore directories)
                files.append(full_path)

        return files

    except Exception as e:
        db_log(environment_id, f"353 - An error occurred: {e}")
        return []


@router.get("/terraform_apply/")
async def terraform_apply():
    removelock()
    return run_terraform_apply()


@router.get("/terraform_init/")
async def terraform_init():
    removelock()
    return run_terraform_init()


async def process_validation_by_job_id(job_id: str, background_tasks: BackgroundTasks):
    # שליפת הנתונים מה-DB
    document = get_from_db(
        project_id=PROJECT_ID,
        database=FIRESTORE_DB,
        collection_name="Requests",
        document_id=job_id
    )

    if not document:
        return {"error": f"373 - No document found for job_id: {job_id}"}

    # שחזור אובייקט הבקשה
    request = ValidationRequestBody(**document["request"])

    # הרצת הפעולות
    set_val_response(job_id)
    background_tasks.add_task(perform_validation, job_id, request)

    return {"message": f"382 - Validation process started for job_id: {job_id}"}


async def process_validation_by_id():
    db_log(environment_id, "387 - process_validation_by_id start")
    try:
        db_log(environment_id, "389 - log every line")
        document = await get_from_db_by_short_id(
            project_id=PROJECT_ID,
            database=FIRESTORE_DB,
            collection_name="Requests",
            short_id=environment_id
        )
        db_log(environment_id, "396 - log every line")
        if not document:
            db_log(environment_id, "394 - request: " + document["request"])
            return {"error": f"394 - No document found for short_id: " + document["job_id"]}
        db_log(environment_id, "400 - log every line")
        if "request" not in document:
            db_log(environment_id, "399 - 'request' key not found in document")
            return {"error": "400 - 'request' key not found in document"}
        db_log(environment_id, "404 - log every line")
        # שחזור אובייקט הבקשה
        request = ValidationRequestBody(**document["request"])
        db_log(environment_id, "407 - log every line")
        # הרצת הפעולות
        set_val_response(document["job_id"])
        db_log(environment_id, "410 - log every line")
        await perform_validation(document["job_id"], request)
        db_log(environment_id, "412 - Validation process started for job_id: " + document["job_id"])
        return {"message": f"Validation process started for job_id: " + document["job_id"]}
    except KeyError as e:
        db_log(environment_id, f"415 - Missing key in document: {e}")
        return {"error": f"416 - Missing key in document: {str(e)}"}
    except Exception as e:
        db_log(environment_id, f"418 - An error occurred: {e}")
        return {"error": f"419 - An error occurred: {str(e)}"}


# דוגמה לשימוש בפונקציה החדשה
@router.post("/process-validation/{job_id}")
async def api_process_validation(job_id: str, background_tasks: BackgroundTasks):
    return await process_validation_by_job_id(job_id, background_tasks)


# פונקציה שמחפשת job ב-DB לפי short_id
async def check_for_job():
    counter = 0  # מונה לריצות הלולאה
    while True:
        db_log(environment_id, f"{datetime.datetime.now()} - Checking for new jobs in DB")
        # שליפת המסמך מה-DB באמצעות await
        document = await get_from_db_by_short_id(
            project_id=PROJECT_ID,
            database=FIRESTORE_DB,
            collection_name="Requests",
            short_id=environment_id
        )
        db_log(environment_id, f"Job {json.dumps(document)} pulled.")
        if document:
            # בדיקה אם המסמך נמשך בעבר (pulled == True)
            if document.get('pulled'):
                db_log(environment_id, f"Job {document['job_id']} already pulled. Stopping timer.")
                break  # מפסיק את הלולאה אם המסמך כבר נמשך
            db_log(environment_id, f"Job found with job_id: {document['job_id']}")
            await process_validation_by_id()
            document['pulled'] = True  # מעדכן שהג'וב נמשך
            await update_job_in_db(document['job_id'], document)  # פונקציית עזר לעדכון ה-DB (async)
            db_log(environment_id, f"Job {document['job_id']} marked as pulled")
            break  # מפסיק את הלולאה לאחר הטיפול ב-Job
        # אם לא מצא ג'וב, מחכה דקה ובודק שוב
        await asyncio.sleep(60)
        counter += 1
        if counter >= 30:
            db_log(environment_id, f"Job check loop ran 30 times. Stopping.")
            break



# פונקציית עזר לעדכון ה-DB (כעת היא async)
def update_job_in_db(job_id, document):
    db_log(environment_id, f"Updating document in DB for job_id: {job_id}")

    # שימוש ב-await לעדכון המסמך ב-DB
    store_on_db(
        project_id=PROJECT_ID,
        database=FIRESTORE_DB,
        collection_name="Requests",
        document_key=job_id,
        params=document
    )


# פונקציה ראשית שמתחילה את התהליך
async def start_job_checking():
    await check_for_job()


async def initialize():
    # db_log(environment_id, str(removelock()))
    init_process = run_terraform_init_background(terraform_directory)
    db_log(environment_id, "417 - Terraform init started in background.")
    if environment_id != "MainServer":
        db_log(environment_id, "419 - In the If (environment_id != MainServer)")
        await start_job_checking()


@router.post("/post_validation_by_id/")
async def post_validation_by_id():
    return await process_validation_by_id()


@router.delete("/delete_terraform_file/{short_id}")
async def delete_terraform_file(short_id: str):
    try:
        # Define the file path using the short_id
        file_path = os.path.join(terraform_directory, f"new-gpu-server-{short_id}.tf")
        db_log(environment_id, f"434 - Attempting to delete file: {file_path}")

        if os.path.exists(file_path):
            os.remove(file_path)
            db_log(environment_id, f"438 - File {file_path} deleted successfully")

            if not os.path.exists(file_path):
                db_log(environment_id, f"441 - File {file_path} confirmed deleted")
            else:
                db_log(environment_id, f"443 - File {file_path} still exists after attempted deletion")
        else:
            db_log(environment_id, f"445 - File {file_path} does not exist, nothing to delete")

        return {"message": f"File {file_path} deleted successfully if it existed"}

    except Exception as e:
        db_log(environment_id, f"315 - Error deleting file {file_path}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error deleting file: {str(e)}")


@router.post("/run_terraform_plan/")
async def run_terraform_plan():
    try:
        result = subprocess.run(
            ["terraform", "plan"],
            cwd=terraform_directory,
            check=True,
            capture_output=True,
            text=True
        )
        db_log(environment_id, "430 - Terraform plan completed successfully.")
        db_log(environment_id, result.stdout)
        return result.stdout
    except subprocess.CalledProcessError as e:
        db_log(environment_id, f"434 - Terraform plan failed !!!!!!!! with error: {e}")
        db_log(environment_id, json.dumps({"error": str(e)}))
        db_log(environment_id, e.stderr)
        return None

def check_command_exists(command):
    return shutil.which(command) is not None

def run_command(command):
    try:
        result = subprocess.run(command, shell=True, check=True, capture_output=True, text=True)
        return result.stdout.strip()
    except subprocess.CalledProcessError as e:
        return f"Error: {e.output.strip()}"

def check_gcloud_config():
    try:
        project = run_command("gcloud config get-value project")
        account = run_command("gcloud config get-value account")
        return f"Project: {project}, Account: {account}"
    except Exception as e:
        return f"Error checking gcloud config: {str(e)}"
    
def check_kubectl_config():
    try:
        context = run_command("kubectl config current-context")
        clusters = run_command("kubectl config get-clusters")
        users = run_command("kubectl config get-users")
        return f"Current context: {context}\nClusters: {clusters}\nUsers: {users}"
    except Exception as e:
        return f"Error checking kubectl config: {str(e)}\n{run_command('kubectl config view')}"

def run_command2(command: str) -> dict:
    """
    Run a command and return detailed output.
    """
    try:
        # Log the command being executed
        db_log(environment_id, f"Executing command: {command}")
        
        # Run the command and capture both stdout and stderr
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True
        )
        
        # Log the complete output
        db_log(environment_id, f"Command stdout: {result.stdout}")
        db_log(environment_id, f"Command stderr: {result.stderr}")
        db_log(environment_id, f"Return code: {result.returncode}")
        
        return {
            "success": result.returncode == 0,
            "stdout": result.stdout.strip(),
            "stderr": result.stderr.strip(),
            "return_code": result.returncode
        }
        
    except Exception as e:
        error_msg = f"Error running command: {str(e)}"
        db_log(environment_id, error_msg)
        return {
            "success": False,
            "error": str(e),
            "stdout": "",
            "stderr": error_msg,
            "return_code": -1
        }

@router.post("/run_command")
async def execute_command(command: str):
    output = run_command2(command)
    db_log(environment_id, f"Command execution result: {output}")
    return {"message": "Command executed", "output": output}
    
@router.delete("/delete_node_pool_and_deployment/{short_id}")
async def delete_node_pool_and_deployment(short_id: str):
    try:
        db_log(environment_id, f"Starting deletion process for short_id: {short_id}")
        
        # 1. Verify credentials are set up
        creds_file = "/tmp/gcloud_keys/service_account_key.json"
        if not os.path.exists(creds_file):
            db_log(environment_id, "Credentials not found, attempting to create...")
            await create_service_account_key()
            await setup_cluster_access()
        
        # 2. Delete deployment
        deployment_name = f"app-deployment-gpu-{short_id}"
        db_log(environment_id, f"Attempting to delete deployment: {deployment_name}")
        
        deployment_cmd = f"""kubectl delete deployment {deployment_name} \
            --namespace=default --grace-period=0 --force"""
        deployment_result = run_command(deployment_cmd)
        db_log(environment_id, f"Deployment deletion result: {deployment_result}")
        
        # 3. Delete node pool
        node_pool_name = f"sc-gpu-{short_id}"
        db_log(environment_id, f"Attempting to delete node pool: {node_pool_name}")
        
        node_pool_cmd = f"""gcloud container node-pools delete {node_pool_name} \
            --cluster=autodefenseml --region=us-central1 --quiet \
            --project=autodefenseml"""
        node_pool_result = run_command(node_pool_cmd)
        db_log(environment_id, f"Node pool deletion result: {node_pool_result}")
        
        return {
            "status": "success",
            "deployment_result": deployment_result,
            "node_pool_result": node_pool_result
        }
        
    except Exception as e:
        error_message = f"Error in delete_node_pool_and_deployment: {str(e)}"
        db_log(environment_id, error_message)
        raise HTTPException(status_code=500, detail=error_message)

@router.post("/addGpuToDB/")
async def addGpuToDB():
    document2 = {"runTerraform": True,
                 "json": '''variable "gpu_num_XXXX" {
      description = "The ID for the duplicate gpu node"
      type        = string
      default     = "YYYY"
    }

    resource "kubernetes_deployment" "api_terraform_gpu_num_XXXX" {
      metadata {
        name = "app-deployment-gpu-${var.gpu_num_XXXX}"
      }

      spec {
        replicas = 1

        selector {
          match_labels = {
            app = "app-gpu-${var.gpu_num_XXXX}"
          }
        }

        template {
          metadata {
            labels = {
              app = "app-gpu-${var.gpu_num_XXXX}"
            }
          }

          spec {
            service_account_name = "k8s-service"

            node_selector = {
              "nodepool" = "sc-gpu-${var.gpu_num_XXXX}",
              "gpu"      = "true${var.gpu_num_XXXX}"
            }

            toleration {
              key      = "nvidia.com/gpu"
              operator = "Equal"
              value    = "present"
              effect   = "NoSchedule"
            }

            container {
              name  = "app-gpu-${var.gpu_num_XXXX}"
              image = "us-central1-docker.pkg.dev/autodefenseml/autodefenseml/app:latest"
              port {
                container_port = 8080
              }

              env {
                name  = "api_terraform_PORT"
                value = "8080"
              }

              env {
                name  = "api_terraform_HOST"
                value = "0.0.0.0"
              }

              env {
                name  = "USER_MNG_URL"
                value = "http://user-manager:80"
              }

              env {
                name  = "SYSTEM_SERVICE_URL"
                value = "http://system-service:80"
              }

              env {
                name  = "GOOGLE_CLOUD_PROJECT"
                value = "autodefenseml"
              }

              env {
                name  = "PROJECT_MNG_URL"
                value = "http://project-manager:80"
              }

              env {
                name  = "CONFIG_MNG_URL"
                value = "http://configuration-manager:80"
              }

              env {
                name  = "VALIDATION_MNG_URL"
                value = "http://validation-manager:80"
              }

              env {
                name  = "EVAL_DETECTION_MNG_URL"
                value = "http://eval-detection-manager:80"
              }

              env {
                name  = "FIREBASE_API_KEY"
                value = "AIzaSyDEOZpCAcrjpJI5MaKB4wECdkjw8V5_bxU"
              }

              env {
                name  = "ENVIRONMENT"
                value = "MainServer"
              }
            }
          }
        }
      }
    }

    resource "google_container_node_pool" "node-gpu_num_XXXX" {
      name               = "sc-gpu-${var.gpu_num_XXXX}"
      cluster            = "projects/autodefenseml/locations/us-central1/clusters/autodefenseml"
      initial_node_count = 1 # Ensure the pool starts with at least 1 node


      management {
        auto_repair  = true
        auto_upgrade = true
      }

      autoscaling {
        min_node_count = 1
        max_node_count = 5
      }

      node_config {
        preemptible  = false
        machine_type = "n1-standard-4" # Adjust the machine type as needed

        guest_accelerator {
          count = 1                 # Number of GPUs per node
          type  = "nvidia-tesla-t4" # Replace with the appropriate GPU type
        }

        # Optional taint configuration
        taint {
          key    = "nvidia.com/gpu"
          value  = "present"
          effect = "NO_SCHEDULE"
        }

        service_account = "kubernetes-test@autodefenseml.iam.gserviceaccount.com"
        oauth_scopes = [
          "https://www.googleapis.com/auth/cloud-platform"
        ]
        tags = ["gke-node"]

        labels = {
          "role"     = "compute"
          "nodepool" = "sc-gpu-${var.gpu_num_XXXX}"
          "gpu"      = "true${var.gpu_num_XXXX}"
        }

        # Add a startup script to install GPU drivers
        metadata = {
          "install-gpu-driver"       = "true"
          "disable-legacy-endpoints" = "true"
        }
      }
    }

    resource "kubernetes_service" "api_terraform_gpu_num_XXXX" {
      metadata {
        name = "api-terraform-service-gpu${var.gpu_num_XXXX}"
        annotations = {
          "cloud.google.com/neg" = jsonencode({
            ingress = true
          })
        }
      }

      spec {
        selector = {
          app = "app-gpu-${var.gpu_num_XXXX}"
        }

        port {
          port        = 80
          target_port = 8080
        }

        type = "LoadBalancer"
      }
    }
    '''}
    return store_on_db(project_id=PROJECT_ID,
                       database=FIRESTORE_DB,
                       collection_name="Stuff",
                       document_key="addGpuServer",
                       params=document2)


@router.post("/aaaaa_testtttt/{idddd}")
async def aaaaa_testtttt(idddd: str):
    while True:
      db_log(environment_id, f"{datetime.datetime.now()} - Checking for new jobs in DB")

      # שליפת המסמך מה-DB באמצעות await
      document = await get_from_db_by_short_id(
          project_id=PROJECT_ID,
          database=FIRESTORE_DB,
          collection_name="Requests",
          short_id=idddd
      )
      db_log(environment_id, f"Job {json.dumps(document)} pulled.2")

      if document:
          # בדיקה אם המסמך נמשך בעבר (pulled == True)
          if document.get('pulled'):
              db_log(environment_id, f"Job {document['job_id']} already pulled. Stopping timer.")
              break  # מפסיק את הלולאה אם המסמך כבר נמשך

          db_log(environment_id, f"Job found with job_id: {document['job_id']}")

          # עדכון ה-DB שה-Job נמשך
          document['pulled'] = True  # מעדכן שהג'וב נמשך
          update_job_in_db(document['job_id'], document)  # פונקציית עזר לעדכון ה-DB (async)

          db_log(environment_id, f"Job {document['job_id']} marked as pulled")
          await process_validation_by_id()
          # מפסיק את הטיימר לאחר שמושך את ה-Job
          break

      # אם לא מצא ג'וב, מחכה דקה ובודק שוב
      await asyncio.sleep(60)

@router.get("/check_gcp_setup")
async def check_gcp_setup():
    try:
        results = {}
        
        # 1. Check gcloud authentication
        db_log(environment_id, "Checking gcloud auth status...")
        results["gcloud_auth"] = run_command("gcloud auth list")
        
        # 2. Check current project
        db_log(environment_id, "Checking current project...")
        results["current_project"] = run_command("gcloud config get-value project")
        
        # 3. Check application default credentials
        db_log(environment_id, "Checking application default credentials...")
        results["default_credentials"] = run_command("gcloud auth application-default print-access-token")
        
        # 4. Check GKE cluster access
        db_log(environment_id, "Checking GKE cluster access...")
        results["cluster_access"] = run_command(
            "gcloud container clusters describe autodefenseml --region=us-central1"
        )
        
        # 5. Check service account
        db_log(environment_id, "Checking active service account...")
        results["service_account"] = run_command(
            "gcloud auth list --filter=status:ACTIVE --format='value(account)'"
        )
        
        # 6. Check IAM roles
        db_log(environment_id, "Checking IAM roles...")
        current_account = results["service_account"]["stdout"]
        if current_account:
            results["iam_roles"] = run_command(
                f"gcloud projects get-iam-policy autodefenseml --flatten='bindings[].members' "
                f"--format='table(bindings.role)' --filter='bindings.members:{current_account}'"
            )
        
        # 7. Try to get kubectl credentials
        db_log(environment_id, "Attempting to get kubectl credentials...")
        results["kubectl_credentials"] = run_command(
            "gcloud container clusters get-credentials autodefenseml --region=us-central1"
        )
        
        # 8. Check kubectl configuration
        db_log(environment_id, "Checking kubectl config...")
        results["kubectl_config"] = run_command("kubectl config view")
        
        # 9. Check specific kubectl permissions
        db_log(environment_id, "Checking specific kubectl permissions...")
        permissions_to_check = [
            "delete deployment",
            "delete node",
            "list pods",
            "list nodes"
        ]
        results["kubectl_permissions"] = {}
        for perm in permissions_to_check:
            results["kubectl_permissions"][perm] = run_command(f"kubectl auth can-i {perm}")
        
        # Create a summary of issues found
        issues = []
        recommendations = []
        
        # Check for common issues and add recommendations
        if not results["gcloud_auth"]["success"]:
            issues.append("Not authenticated with gcloud")
            recommendations.append("Run 'gcloud auth login'")
            
        if not results["default_credentials"]["success"]:
            issues.append("No application default credentials")
            recommendations.append("Run 'gcloud auth application-default login'")
            
        if not results["cluster_access"]["success"]:
            issues.append("Cannot access GKE cluster")
            recommendations.append("Verify you have the 'container.clusters.get' permission")
            
        if not results["kubectl_credentials"]["success"]:
            issues.append("Cannot get kubectl credentials")
            recommendations.append("Verify your GCP credentials and cluster access")
            
        # Add the summary to results
        results["summary"] = {
            "issues_found": issues,
            "recommendations": recommendations
        }
        
        db_log(environment_id, f"Complete GCP setup check results: {results}")
        return results
        
    except Exception as e:
        error_message = f"Error checking GCP setup: {str(e)}"
        db_log(environment_id, error_message)
        raise HTTPException(status_code=500, detail=error_message)
    

@router.post("/setup_cluster_access")
async def setup_cluster_access():
    try:
        results = {}
        db_log(environment_id, "Starting cluster access setup")
        
        # 1. Make sure we're using the right credentials
        creds_file = "/tmp/gcloud_keys/service_account_key.json"
        if not os.path.exists(creds_file):
            raise Exception(f"Credentials file not found at {creds_file}. Please run create_service_account_key first.")
        
        # 2. Set explicit credentials
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = creds_file
        db_log(environment_id, f"Using credentials from {creds_file}")
        
        # 3. Configure docker credentials
        docker_cmd = "gcloud auth configure-docker"
        results["docker_auth"] = run_command(docker_cmd)
        db_log(environment_id, f"Docker auth result: {results['docker_auth']}")
        
        # 4. Configure GKE credentials without metadata server
        cluster_cmd = (
            "gcloud container clusters get-credentials autodefenseml "
            "--region=us-central1 --project=autodefenseml "
            "--no-use-metadata-server"
        )
        results["cluster_auth"] = run_command(cluster_cmd)
        db_log(environment_id, f"Cluster auth result: {results['cluster_auth']}")
        
        # 5. Create the necessary RBAC roles
        rbac_commands = [
            # Create a ClusterRole if it doesn't exist
            """kubectl create clusterrole node-admin --verb=get,list,delete,create,watch,patch \
               --resource=nodes,deployments,services,pods --dry-run=client -o yaml | kubectl apply -f -""",
            
            # Create ClusterRoleBinding
            f"""kubectl create clusterrolebinding sa-node-admin \
               --clusterrole=node-admin \
               --user=kubernetes-test@autodefenseml.iam.gserviceaccount.com \
               --dry-run=client -o yaml | kubectl apply -f -"""
        ]
        
        results["rbac"] = {}
        for i, cmd in enumerate(rbac_commands):
            results["rbac"][f"command_{i}"] = run_command(cmd)
            db_log(environment_id, f"RBAC command {i} result: {results['rbac'][f'command_{i}']}")
        
        # 6. Verify setup
        verify_commands = {
            "current_context": "kubectl config current-context",
            "cluster_info": "kubectl cluster-info",
            "auth_check": "kubectl auth can-i delete node",
            "list_nodes": "kubectl get nodes"
        }
        
        results["verification"] = {}
        for name, cmd in verify_commands.items():
            results["verification"][name] = run_command(cmd)
            db_log(environment_id, f"Verification {name} result: {results['verification'][name]}")
        
        return results
        
    except Exception as e:
        error_message = f"Error setting up cluster access: {str(e)}"
        db_log(environment_id, error_message)
        raise HTTPException(status_code=500, detail=error_message)

@router.post("/create_service_account_key")
async def create_service_account_key():
    try:
        results = {}
        service_account = "kubernetes-test@autodefenseml.iam.gserviceaccount.com"
        
        db_log(environment_id, "Starting service account key creation process")
        
        # 1. Create key directory if it doesn't exist
        mkdir_cmd = "mkdir -p /tmp/gcloud_keys"
        results["mkdir"] = run_command(mkdir_cmd)
        db_log(environment_id, f"Create directory result: {results['mkdir']}")
        
        # 2. Create a new key for the service account
        key_file = "/tmp/gcloud_keys/service_account_key.json"
        key_cmd = f"gcloud iam service-accounts keys create {key_file} --iam-account={service_account}"
        results["key_creation"] = run_command(key_cmd)
        db_log(environment_id, f"Key creation result: {results['key_creation']}")
        
        if results["key_creation"]["success"]:
            # 3. Set environment variable
            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = key_file
            db_log(environment_id, f"Set GOOGLE_APPLICATION_CREDENTIALS to {key_file}")
            
            # 4. Authenticate using the new key
            auth_cmd = f"gcloud auth activate-service-account --key-file={key_file}"
            results["authentication"] = run_command(auth_cmd)
            db_log(environment_id, f"Authentication result: {results['authentication']}")
            
            # 5. Verify authentication
            verify_cmd = "gcloud auth list"
            results["verify_auth"] = run_command(verify_cmd)
            db_log(environment_id, f"Auth verification result: {results['verify_auth']}")
            
            # 6. Set the project
            project_cmd = "gcloud config set project autodefenseml"
            results["project_setup"] = run_command(project_cmd)
            db_log(environment_id, f"Project setup result: {results['project_setup']}")
        
        return results
        
    except Exception as e:
        error_message = f"Error creating service account key: {str(e)}"
        db_log(environment_id, error_message)
        raise HTTPException(status_code=500, detail=error_message)
    

@router.delete("/delete_node_pool/{short_id}")
async def delete_node_pool(short_id: str):
    try:
        # First verify the node pool exists
        check_command = f"gcloud container node-pools list --cluster=autodefenseml --region=us-central1 --filter=name:sc-gpu-{short_id}"
        check_result = run_command_with_details(check_command)
        
        if not check_result["success"] or not check_result["stdout"]:
            return {
                "message": "Node pool not found",
                "details": check_result,
                "short_id": short_id
            }

        # Try different methods to delete the node pool
        methods = [
            # Method 1: Standard delete
            f"gcloud container node-pools delete sc-gpu-{short_id} --cluster=autodefenseml --region=us-central1 --quiet",
            
            # Method 2: Delete with async flag
            f"gcloud container node-pools delete sc-gpu-{short_id} --cluster=autodefenseml --region=us-central1 --quiet --async",
            
            # Method 3: Delete with timeout
            f"gcloud container node-pools delete sc-gpu-{short_id} --cluster=autodefenseml --region=us-central1 --quiet --timeout=10m"
        ]

        results = []
        success = False

        for method in methods:
            db_log(environment_id, f"Attempting node pool deletion with command: {method}")
            result = run_command_with_details(method)
            results.append({
                "method": method,
                "result": result
            })
            
            if result["success"]:
                success = True
                break
            
            # Wait a bit before trying the next method
            await asyncio.sleep(5)

        # Verify deletion
        verify_command = f"gcloud container node-pools list --cluster=autodefenseml --region=us-central1 --filter=name:sc-gpu-{short_id}"
        verification = run_command_with_details(verify_command)
        
        # Check if the node pool still exists
        node_pool_gone = not verification["stdout"] or "not found" in verification["stderr"].lower()

        # Get cluster status for additional context
        cluster_status = run_command_with_details(
            "gcloud container clusters describe autodefenseml --region=us-central1"
        )

        detailed_response = {
            "message": "Node pool deletion completed" if success or node_pool_gone else "Node pool deletion failed",
            "deletion_attempts": results,
            "final_verification": verification,
            "cluster_status": cluster_status,
            "node_pool_id": f"sc-gpu-{short_id}",
            "success": success or node_pool_gone
        }

        # Log the detailed response
        db_log(environment_id, f"Node pool deletion detailed response: {json.dumps(detailed_response, indent=2)}")

        if not success and not node_pool_gone:
            # Try one last emergency deletion if everything else failed
            emergency_delete = run_command_with_details(
                f"gcloud container node-pools delete sc-gpu-{short_id} "
                f"--cluster=autodefenseml --region=us-central1 --quiet "
                f"--async --no-wait"
            )
            detailed_response["emergency_attempt"] = emergency_delete

        return detailed_response

    except Exception as e:
        error_traceback = traceback.format_exc()
        error_message = {
            "error": str(e),
            "traceback": error_traceback,
            "short_id": short_id
        }
        db_log(environment_id, f"Error in delete_node_pool: {json.dumps(error_message, indent=2)}")
        raise HTTPException(status_code=500, detail=error_message)


def run_command_with_details(command: str) -> dict:
    """
    Run a command and return detailed output including stderr and return code
    """
    try:
        process = subprocess.run(
            command,
            shell=True,
            text=True,
            capture_output=True,
            check=False  # Don't raise exception on non-zero return code
        )
        return {
            "success": process.returncode == 0,
            "return_code": process.returncode,
            "stdout": process.stdout.strip() if process.stdout else "",
            "stderr": process.stderr.strip() if process.stderr else "",
            "command": command
        }
    except Exception as e:
        return {
            "success": False,
            "return_code": -1,
            "stdout": "",
            "stderr": str(e),
            "command": command
        }

@router.delete("/delete_deployment/{short_id}")
async def delete_deployment(short_id: str):
    try:
        # Try multiple methods to delete the deployment
        methods = [
            # Method 1: Normal delete
            f"kubectl delete deployment app-deployment-gpu-{short_id} --namespace=default",
            
            # Method 2: Force delete
            f"kubectl delete deployment app-deployment-gpu-{short_id} --namespace=default --force --grace-period=0",
            
            # Method 3: Delete using yaml definition
            f"kubectl delete -f <(kubectl get deployment app-deployment-gpu-{short_id} -o yaml)",
            
            # Method 4: Using kubectl patch
            f"kubectl patch deployment app-deployment-gpu-{short_id} -p '{{\"metadata\":{{\"finalizers\":[]}}}}' --type=merge"
        ]

        results = []
        deployment_exists = run_command_with_details(f"kubectl get deployment app-deployment-gpu-{short_id}")
        
        if "NotFound" in deployment_exists.get("stderr", ""):
            return {"message": "Deployment not found", "details": deployment_exists}

        for method in methods:
            result = run_command_with_details(method)
            results.append(result)
            if result["success"]:
                break

        # Log detailed results
        db_log(environment_id, f"Deployment deletion attempts results: {json.dumps(results, indent=2)}")

        # Check if deployment still exists
        final_check = run_command_with_details(f"kubectl get deployment app-deployment-gpu-{short_id}")
        
        return {
            "message": "Deployment deletion process completed",
            "attempts": results,
            "final_status": final_check,
            "success": "NotFound" in final_check.get("stderr", "") or final_check.get("success", False)
        }

    except Exception as e:
        error_message = f"Error in delete_deployment: {str(e)}"
        db_log(environment_id, error_message)
        raise HTTPException(status_code=500, detail=error_message)

@router.post("/execute_command")
async def execute_command(command: str):
    """
    Execute any command with detailed output
    """
    try:
        # Security check - add any security validations here
        forbidden_commands = ["rm", "mkfs", "dd", ">", ">>", "|", "&"]
        if any(cmd in command for cmd in forbidden_commands):
            raise HTTPException(
                status_code=400, 
                detail="Command contains forbidden operations"
            )

        result = run_command_with_details(command)
        
        # Log the execution
        db_log(environment_id, f"Command execution: {command}")
        db_log(environment_id, f"Result: {json.dumps(result, indent=2)}")

        if not result["success"]:
            # Return as 200 but with error details in the response
            return {
                "status": "error",
                "command": command,
                "details": result,
                "message": f"Command failed with return code {result['return_code']}"
            }

        return {
            "status": "success",
            "command": command,
            "details": result,
            "message": "Command executed successfully"
        }

    except Exception as e:
        error_message = f"Error executing command: {str(e)}"
        db_log(environment_id, error_message)
        raise HTTPException(status_code=500, detail=error_message)

# כדאי גם לעדכן את delete_node_pool_and_deployment להשתמש בפונקציונליות החדשה
@router.delete("/delete_node_pool_and_deployment/{short_id}")
async def delete_node_pool_and_deployment(short_id: str):
    try:
        checks = []
        
        # Check if gcloud and kubectl are installed
        if not check_command_exists("gcloud"):
            checks.append("gcloud is not installed or not in PATH")
        if not check_command_exists("kubectl"):
            checks.append("kubectl is not installed or not in PATH")
        
        # Check gcloud and kubectl configurations
        gcloud_config = check_gcloud_config()
        kubectl_config = check_kubectl_config()
        checks.append(f"gcloud config: {gcloud_config}")
        checks.append(f"kubectl config: {kubectl_config}")
        
        cluster_check = run_command_with_details("gcloud container clusters describe autodefenseml --region us-central1")
        checks.append(f"Cluster check: {'Exists' if cluster_check['success'] else 'Not found'}")
        
        if "is not installed" in "\n".join(checks) or "Not found" in checks[-1]:
            raise Exception("Required tools are not installed or cluster not found")
        
        if checks:
            db_log(environment_id, "Preliminary checks:\n" + "\n".join(checks))
        
        # Delete node pool first
        node_pool_command = f"gcloud container node-pools delete sc-gpu-{short_id} --cluster=autodefenseml --region=us-central1 --quiet"
        node_pool_result = run_command_with_details(node_pool_command)
        db_log(environment_id, f"Node pool deletion result: {json.dumps(node_pool_result, indent=2)}")
        
        # Wait for 30 seconds after node pool deletion
        if node_pool_result["success"]:
            await asyncio.sleep(30)
        
        # Then delete deployment with the new improved method
        deployment_result = await delete_deployment(short_id)
        
        return {
            "message": "Node pool and deployment deletion process completed",
            "node_pool_result": node_pool_result,
            "deployment_result": deployment_result,
            "preliminary_checks": checks
        }

    except Exception as e:
        error_message = f"Error in delete_node_pool_and_deployment: {str(e)}"
        db_log(environment_id, error_message)
        raise HTTPException(status_code=500, detail=error_message)